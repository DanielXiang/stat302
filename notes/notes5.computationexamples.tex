\documentclass[11pt]{article}
\def \baselinestretch{1.2}
\usepackage{amsmath}
\usepackage{graphicx}

\def\B{\text{Beta}}
%\def\ni{\noindent}
%\textwidth=18.0cm
%\topmargin=-1.2cm
%\columnsep=1.0cm
%\textheight=21.8cm
%\hoffset=-1.9cm

\setcounter{secnumdepth}{2}
\renewcommand{\baselinestretch}{1.2}
\setlength{\parindent}{0.3in}
\setlength{\parskip}{0.1in}


%\setcounter{section}{3}


\begin{document}
%\twocolumn
\normalsize


\section{Example 1: computing the posterior for a discrete distribution}

Suppose we are interested in estimating the number of different fish in a particular lake. We extract 50 fish, and mark them. The a week later
we extract another 50 fish, and count how many of them have marks.  
This approach is called "Capture-Mark-Recapture"
Suppose $X$ of them are marked, and we want to compute the posterior distribution on the number of fish.	

I am going to use a prior $p(N) \propto 1/N$ for $N=50,\dots,10^6$. Note that this is approximately
uniform on the log scale, so represents being uncertain about $N$ over orders of magnitude.

The likelihood is the number of ways of drawing 50 with $X$ marked and $50-X$ unmarked, divided by the total number of ways of drawing 50 fish.
\begin{equation}
P(X|N) = \frac{{50 \choose X} {N-50 \choose 50-X} } {{N \choose 50}}
\end{equation}

Here's example R code for $X=1$:
\begin{verbatim}
N=50:10^6
X=1 # for example!
prior = 1/N
prior = prior/sum(prior)
lik = choose(N-50,50-X)/choose(N,50) #I dropped the term not depending on N
post = prior*lik
post=post/sum(post) #normalize to sum to 1
\end{verbatim}

Now we can compute the probability that N lies in any given interval. For example
\begin{verbatim}
sum(post[N<10^4])
[1] 0.7798534
\end{verbatim}
so our posterior probability that there are fewer than 10,000 fish is about 0.78.


\section{Example 2: Computation by naive Monte Carlo}

This example is modeled on an example from Jim Berger.

Suppose we have an imperfect test for whether someone is affected
with a condition (eg a virus). 
Let $f$ be the overall prevalence of the condition,
$p_0$ be the probability of a positive test result when the individual is unaffected, $p_1$ be the probability of a positive test result if the individual is affected.

Given a positive test result the probability of being affected is $$p_A := fp_1/ (fp_1+(1-f)p_0).$$

Now suppose $f$, $p_0$ and $p_1$ are not known with certainty, but estimated based on the following pilot samples. 
\begin{itemize}
\item For $f$: 1 out of 100 individuals were affected.
\item For $p_0$: 1 out of 10 unaffected individuals gave a positive result when tested.
\item For $p_1$: 8 out of 10 affected individuals gave a positive result when tested.
\end{itemize}

Assuming independent  Beta(0.5,0.5) priors on $f,p_0,p_1$ the posteriors given these pilot data are also independent and $f\sim \B(1.5,99.5)$, $p_0 \sim \B(1.5,9.5)$ and $p_1\sim \B(8.5,2.5)$.

Because it is straightforward to simulated form these posterior distributions, we can easily estimate a posterior median and 95\% Credible Interval for $p_A$ by naive Monte Carlo simulation from the posterior:
\begin{verbatim}
Nsim=10000
f = rbeta(Nsim,1.5,99.5)
p0= rbeta(Nsim,1.5,9.5)
p1= rbeta(Nsim,8.5,2.5)
pA = f*p1/(f*p1+(1-f)*p0)
quantile(pA,c(0.025,0.5,0.975))

       2.5%         50%       97.5% 
0.005374967 0.074966382 0.542589567 
\end{verbatim}
Note: the posterior of $p_A$ (Figure \ref{post.pA}) is sufficiently skew that the symmetric interval is not ideal here, but it is simple.
 
 \begin{figure}
 \includegraphics[width=4in]{pAhist.pdf}  \caption{Histograph of posterior samples of $p_A$ from example 2} \label{post.pA}

\end{figure}



\section{Example 3: Naive Monte Carlo vs Importance Sampling}

This example is entirely artificial, to illustrate importance sampling. Throughout we assume that $X \sim \B(2,2)$. Suppose we want to estimate the probability that $X<0.25$. We can do it easily by naive Monte Carlo simulation:
\begin{verbatim}
mean(rbeta(10000,2,2)<0.25)
[1] 0.1522
> pbeta(.25,2,2)
[1] 0.15625
\end{verbatim}
The correct answer is $0.15625$, so we're getting reasonable accuracy from the Monte Carlo estimate with only 10,000 simulations.

But if we want to estimate the probability that
$X<0.001$ we have more trouble:
\begin{verbatim}
> mean(rbeta(10000,2,2)<0.0001)
[1] 0
> pbeta(0.0001,2,2)
[1] 2.9998e-08
 \end{verbatim}
Well you might argue that 0 is not a bad estimate in absolute terms, but the {\it relative} error is large,
and sometimes we might care about this.

Here importance sampling can help. The intuition is that we need to sample from a distribution that has more mass $< 0.0001$. How about Beta(0.5,0.5)?
\begin{verbatim}
y = rbeta(10000,0.5,0.5)
w = dbeta(y,2,2)/dbeta(y,0.5,0.5) 
mean(w*(y<0.0001))
[1] 2.727679e-08
sd(w*(y<0.0001))
[1] 5.434473e-07
\end{verbatim}
which is at least the right order of magnitude.
But the standard deviation of the estimator is rather large, and we can do better. Note in particular that
the Beta(0.5,0.5) spends a lot of it's time sampling parts of the space where the summands ($w I(y<0.001)$)are 0. Recall, also, that the optimal IS distribution is proportional to $\B(2,2)I(X<0.0001)$. Based on this, let's try uniform on (0,0.0001).
\begin{verbatim}
y = runif(10000,0,0.0001)
w = dbeta(y,2,2)/dunif(y,0,0.0001) 
> mean(w*(y<0.0001))
[1] 2.959391e-08 
> sd(w*(y<0.0001))
[1] 1.732338e-08
\end{verbatim}
which we can see gives better accuracy and lower standard error.




\end{document}



