load("../../data/seeb/four_salmon_pops.rda")
set.seed(100) #to ensure reproducibility
nsamp = nrow(four_salmon_pops)
set.seed(100) #to ensure reproducibility
nsamp = nrow(four_salmon_pops)
subset = sample(1:nsamp,nsamp/2,replace=FALSE)
train = four_salmon_pops[subset,]
test = four_salmon_pops[!subset,]
load("../../data/seeb/four_salmon_pops.rda")
set.seed(100) #to ensure reproducibility
nsamp = nrow(four_salmon_pops)
subset = rbinom(nsamp,1,0.5) #include each fish in subset with probability 0.5
train = four_salmon_pops[subset,]
test = four_salmon_pops[!subset,]
table(train[,2])
table(test[,2])
subset = (rbinom(nsamp,1,0.5)==1) #include each fish in subset with probability 0.5
train = four_salmon_pops[subset,]
test = four_salmon_pops[!subset,]
set.seed(100) #to ensure reproducibility
nsamp = nrow(four_salmon_pops)
subset = (rbinom(nsamp,1,0.5)==1) #include each fish in subset with probability 0.5
train = four_salmon_pops[subset,]
test = four_salmon_pops[!subset,]
head(test)
table(test[,2])
table(train[,2])
compute_freqs = function(locus){
alleles = unique(four_salmon_pops[,1+2*locus, 2+2*locus])
return(alleles)
}
compute_freqs(1)
compute_freqs(2)
?unique
compute_freqs = function(data,locus){
return(table(data[,1+2*locus, 2+2*locus]))
}
compute_freqs(train,1)
compute_freqs(train,2)
compute_freqs(test,2)
names(compute_freqs(test,1))
compute_freqs(test,1)["218"]
compute_freqs(test,1)[test[,3]]
test[,3]
compute_freqs(test,1)[as.character(test[,3])]
levels= function(locus){four_salmon_pops([,1+2*locus, 2+2*locus])}
levels= function(locus){levels(factor(four_salmon_pops[,1+2*locus, 2+2*locus]))}
mylevels= function(locus){levels(factor(four_salmon_pops[,1+2*locus, 2+2*locus]))}
rm(levles)
rm(levels)
mylevels= function(locus){levels(factor(four_salmon_pops[,1+2*locus, 2+2*locus]))}
mylevels(1)
mylevels(2)
mylevels(3)
for(locus in 1:12){
four_salmon_pops[,1+2*locus]= factor(four_salmon_pops[,1+2*locus],levels = levels(locus))
four_salmon_pops[,2+2*locus]= factor(four_salmon_pops[,2+2*locus],levels = levels(locus))
}
four_salmon_pops[,3]
mylevels= function(locus){levels(factor(four_salmon_pops[,1+2*locus, 2+2*locus]))}
for(locus in 1:12){
four_salmon_pops[,1+2*locus]= factor(four_salmon_pops[,1+2*locus],levels = mylevels(locus))
four_salmon_pops[,2+2*locus]= factor(four_salmon_pops[,2+2*locus],levels = mylevels(locus))
}
four_salmon_pops[,3]
load("../../data/seeb/four_salmon_pops.rda")
set.seed(100) #to ensure reproducibility
#Convert the data at each locus to a factor
#Note that we have to be careful to include all the levels from *both* columns
#for each locus
mylevels= function(locus){levels(factor(four_salmon_pops[,1+2*locus, 2+2*locus]))}
for(locus in 1:12){
four_salmon_pops[,1+2*locus]= factor(four_salmon_pops[,1+2*locus],levels = mylevels(locus))
four_salmon_pops[,2+2*locus]= factor(four_salmon_pops[,2+2*locus],levels = mylevels(locus))
}
four_salmon_pops[,3]
nsamp = nrow(four_salmon_pops)
subset = (rbinom(nsamp,1,0.5)==1) #include each fish in subset with probability 0.5
train = four_salmon_pops[subset,]
test = four_salmon_pops[!subset,]
#a function to compute the alleles and their frequency at a given locus (locus= 1...12)
compute_freqs = function(data,locus){
return(table(data[,1+2*locus, 2+2*locus],levels=levels))
}
?table
compute_freqs = function(data,locus){
return(table(data[,1+2*locus, 2+2*locus]))
}
compute_freqs(test,1)
compute_freqs(train,1)
compute_freqs(test,2)
compute_freqs(train,2)
compute_freqs(test,3)
compute_freqs(train,3)
compute_freqs(train,1)
test[,3]
for(i in 1:locus){trainfreq[[i]]= compute_freqs(train,i)}
trainfreq = list()
for(i in 1:locus){trainfreq[[i]]= compute_freqs(train,i)}
trainfreq[[1]]
trainfreq[[2]]
normalize= function(x){x/sum(x)}
lapply(trainfreq,normalize)
trainf[[1]][test[,3]]
trainf = lapply(trainfreq,normalize)
trainf[[1]][test[,3]]
test[,3]
trainf[[1]][test[,3]]
source('~/Documents/git/stat302/exercises/seeb/train_test.R', echo=TRUE)
trainf[[1]]
sum(trainf[[1]])
load("../../data/seeb/four_salmon_pops.rda")
set.seed(100) #to ensure reproducibility
#Convert the data at each locus to a factor
#Note that we have to be careful to include all the levels from *both* columns
#for each locus
mylevels= function(locus){levels(factor(four_salmon_pops[,1+2*locus, 2+2*locus]))}
for(locus in 1:12){
four_salmon_pops[,1+2*locus]= factor(four_salmon_pops[,1+2*locus],levels = mylevels(locus))
four_salmon_pops[,2+2*locus]= factor(four_salmon_pops[,2+2*locus],levels = mylevels(locus))
}
#Randomly divide the data into a training set and a test set
nsamp = nrow(four_salmon_pops)
subset = (rbinom(nsamp,1,0.5)==1) #include each fish in subset with probability 0.5
train = four_salmon_pops[subset,]
test = four_salmon_pops[!subset,]
#this function computes a table of the alleles and their counts at a given locus (locus= 1...12)
#in a given data frame (data)
compute_counts = function(data,locus){
return(table(data[,1+2*locus, 2+2*locus]))
}
#Here's an example of how this can be used
#to compute the allele frequencies (both the counts and the proportions) in the training set
trainc = list()
for(i in 1:locus){trainc[[i]]= compute_counts(train,i)}
normalize= function(x){x/sum(x)}
trainf = lapply(trainc,normalize) #compute the proportions, or relative frequencies, from counts
#Here is the Exercise:
#The idea is that you want to see if you can correctly classify the individuals in the test set
#based on the information in the training set.
#1. At each locus, use the training set to estimate the allele frequencies (ie proportions) in each of the four subpopulations.
#Assume for the remainder of this exercise that these allele frequencies from the training set are the "true" frequencies in each population.
#2. For each individual in the test data set, compute the posterior probability that it arose from each of the four populations, assuming
# that all four populations are equally likely a priori. You can assume that the 12 loci contribute independently to the likelihood. THat is, the likelihood is defined
# by multiplying the likelihood across loci.
#3. If you ``assign" each individual in the test set to the population that maximizes its posterior probability,
# what is the error rate? (ie how many individuals are misassigned vs correctly assigned?)
#4. Comment on any problems you came across as you did this exercise, and how you solved them. Your answer
#should include all your R code in a format that can be run to reproduce your results (I recommend using RStudio and
#the knitr package to produce your report).
